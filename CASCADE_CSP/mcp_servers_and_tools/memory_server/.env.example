# Memory Server Configuration
# Copy this file to .env and fill in your values

# ============== REQUIRED ==============

# OpenAI API Key (required for LLM-based fact extraction)
OPENAI_API_KEY=sk-your-openai-api-key

# Supabase Configuration (Vector Store)
# Get this from Supabase Dashboard: Connect -> Session pooler
SUPABASE_DATABASE_URL=postgresql://postgres:your-password@db.your-project.supabase.co:5432/postgres

# ============== OPTIONAL ==============

# LLM Configuration
# Set MEM0_USE_LLM=false to disable LLM-based fact extraction (saves API costs)
MEM0_USE_LLM=true
MEM0_LLM_MODEL=gpt-4o-mini

# Neo4j Configuration (Graph Store)
# Required only if ENABLE_GRAPH_MEMORY=true
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-neo4j-password

# Graph Memory Toggle
# Set to 'false' to disable graph memory and use only vector-based search
ENABLE_GRAPH_MEMORY=true

# Server Configuration
HOST=127.0.0.1
PORT=8053
