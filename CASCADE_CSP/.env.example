# CASCADE Environment Variables
# Copy this file to .env and fill in your values: cp .env.example .env
# Priority: .env file > shell environment (.bashrc) > code defaults

# ============== API KEYS ==============

OPENAI_API_KEY=sk-your-openai-api-key
# https://www.tavily.com/
TAVILY_API_KEY=tvly-your-tavily-api-key
# https://next-gen.materialsproject.org/
MP_API_KEY=your-materials-project-api-key

# ============== SUPABASE ==============
# See README.md for how to get these credentials

SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_KEY=your-supabase-service-role-key
SUPABASE_DATABASE_URL=postgresql://postgres:your-password@db.your-project.supabase.co:5432/postgres

# ============== NEO4J ==============

NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-neo4j-password
# Enable knowledge graph for code parsing (requires Neo4j to be running)
USE_KNOWLEDGE_GRAPH=true
# Generate AI summaries for extracted code (optional, increases API usage)
# GENERATE_CODE_SUMMARY=false

# ============== MODEL CONFIGURATION ==============

# Model name for AI agents
AGENT_MODEL_NAME=o3

# OpenAI-compatible API base URL
# OPENAI_BASE_URL=https://api.openai.com/v1

# For vLLM or other local models, uncomment and set:
# OPENAI_BASE_URL=http://localhost:8000/v1
# REQUIRE_OPENAI_API_KEY=false
# USE_ADAPTIVE_AGENTS=true

# ============== MEMORY CONFIGURATION ==============

MEM0_USE_LLM=true
MEM0_LLM_MODEL=gpt-4o-mini
ENABLE_GRAPH_MEMORY=true

# ============== MLFLOW ==============

MLFLOW_TRACKING_URI=http://localhost:5001

# ============== APPLICATION PATHS (usually no need to change) ==============

# PROJECT_ROOT=/app
# CODE_STORAGE_DIR=/app/temp_code
# SAVED_FILES_DIR=/app/saved_code

# ============== DOCKER USER MAPPING ==============
# Required for correct file permissions in Docker containers
# Run these commands to find your values:
#   id -u    (prints your UID)
#   id -g    (prints your GID)

UID=1000
GID=1000
